import re
from typing import List
from loguru import logger


def is_valid_solana_address(address: str) -> bool:
    """–°—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ Solana –∞–¥—Ä–µ—Å–∞ —Å base58 –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    if not address or not isinstance(address, str):
        return False

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã (32-44 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è base58)
    if len(address) < 32 or len(address) > 44:
        return False

    # –ù–∞–±–æ—Ä —Å–∏–º–≤–æ–ª–æ–≤ Base58 (–∏—Å–∫–ª—é—á–∞–µ—Ç 0, O, I, l –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—É—Ç–∞–Ω–∏—Ü—ã)
    base58_chars = set('123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz')
    if not all(c in base58_chars for c in address):
        return False

    # –ò—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–≤–∏–¥–Ω—ã–µ –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
    if address == '1' * len(address):  # –í—Å–µ –µ–¥–∏–Ω–∏—Ü—ã
        return False
    if len(set(address)) < 8:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        return False

    # –ö–†–ò–¢–ò–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –†–µ–∞–ª—å–Ω–æ–µ base58 –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
    try:
        import base58
        decoded = base58.b58decode(address)
        # Solana –∞–¥—Ä–µ—Å–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–æ–≤–Ω–æ 32 –±–∞–π—Ç–∞
        if len(decoded) != 32:
            return False
        return True
    except Exception:
        return False


def is_wrapped_sol(address: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∞–¥—Ä–µ—Å Wrapped SOL"""
    return address == 'So11111111111111111111111111111111111111112'


def filter_trading_targets(addresses: List[str]) -> List[str]:
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ (–∏—Å–∫–ª—é—á–∞–µ–º SOL –∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã)"""
    filtered = []

    # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ø–æ–∫—É–ø–∞–µ–º
    base_tokens = {
        'So11111111111111111111111111111111111111112',  # Wrapped SOL
        'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v',  # USDC
        'Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB',  # USDT
        '11111111111111111111111111111112',  # System Program
    }

    for addr in addresses:
        if addr not in base_tokens:
            logger.info(f"‚úÖ –¶–µ–ª–µ–≤–æ–π —Ç–æ–∫–µ–Ω –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏: {addr}")
            filtered.append(addr)
        else:
            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ç–æ–∫–µ–Ω: {addr}")

    return filtered


def extract_jupiter_swap_addresses(text: str) -> List[str]:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è Jupiter swap —Å—Å—ã–ª–æ–∫ —Å —Å—Ç—Ä–æ–≥–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    addresses = []

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö DEX —Å—Å—ã–ª–æ–∫
    dex_indicators = ['jup.ag', 'jupiter', 'raydium', 'dexscreener', 'birdeye', 'pump.fun']
    if not any(indicator in text.lower() for indicator in dex_indicators):
        return addresses

    logger.debug(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã DEX —Å—Å—ã–ª–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ: {text}")

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö DEX
    jupiter_patterns = [
        # –û—Å–Ω–æ–≤–Ω—ã–µ Jupiter –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        r'jup\.ag/swap/([A-HJ-NP-Za-km-z1-9]{32,44})-([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'jup\.ag/swap\?.*?(?:inputMint|outputMint)=([A-HJ-NP-Za-km-z1-9]{32,44})',

        # –ù–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–Ω–æ–ø–æ–∫/redirect —Å—Å—ã–ª–æ–∫
        r'jupiter[^?\s]*?([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'[?&]token=([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'[?&]mint=([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'[?&]address=([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'[?&]ca=([A-HJ-NP-Za-km-z1-9]{32,44})',

        # –î—Ä—É–≥–∏–µ DEX
        r'raydium\.io[^\s]*?([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'dexscreener\.com/solana/([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'birdeye\.so/token/([A-HJ-NP-Za-km-z1-9]{32,44})',
        r'pump\.fun[^\s]*?([A-HJ-NP-Za-km-z1-9]{32,44})',
    ]

    for pattern in jupiter_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã –∏–∑ –º–∞—Ç—á–∞
            for group in match.groups():
                if group and is_valid_solana_address(group):
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º Wrapped SOL
                    if not is_wrapped_sol(group):
                        logger.info(f"‚úÖ Jupiter —Ç–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω: {group}")
                        addresses.append(group)
                    else:
                        logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Wrapped SOL: {group}")

    # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –ø—Ä–æ–±—É–µ–º —Ä—É—á–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥
    if not addresses:
        addresses.extend(manual_jupiter_parsing(text))

    return addresses


def extract_addresses_from_any_url(url: str) -> List[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤ –∏–∑ –ª—é–±—ã—Ö URL (–≤–∫–ª—é—á–∞—è redirect —Å—Å—ã–ª–∫–∏)"""
    addresses = []

    try:
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø—Ä—è–º—ã–µ –∞–¥—Ä–µ—Å–∞ –≤ URL
        direct_addresses = extract_jupiter_swap_addresses(url)
        addresses.extend(direct_addresses)

        # –ò—â–µ–º –∞–¥—Ä–µ—Å–∞ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö URL
        import re
        from urllib.parse import urlparse, parse_qs

        parsed = urlparse(url)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º query –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if parsed.query:
            params = parse_qs(parsed.query)
            for key, values in params.items():
                if key.lower() in ['token', 'mint', 'address', 'ca', 'contract']:
                    for value in values:
                        if is_valid_solana_address(value):
                            addresses.append(value)
                            logger.info(f"‚úÖ –ê–¥—Ä–µ—Å –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ {key}: {value}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å URL
        path_parts = parsed.path.split('/')
        for part in path_parts:
            if is_valid_solana_address(part):
                addresses.append(part)
                logger.info(f"‚úÖ –ê–¥—Ä–µ—Å –∏–∑ –ø—É—Ç–∏ URL: {part}")

    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL {url}: {e}")

    return list(set(addresses))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

def manual_jupiter_parsing(text: str) -> List[str]:
    """–†—É—á–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ Jupiter —Å—Å—ã–ª–æ–∫ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
    addresses = []

    try:
        # –ò—â–µ–º —á–∞—Å—Ç–∏ URL –ø–æ—Å–ª–µ jup.ag/swap/
        parts = text.lower().split('jup.ag/swap/')
        if len(parts) < 2:
            return addresses

        # –ë–µ—Ä–µ–º —á–∞—Å—Ç—å –ø–æ—Å–ª–µ jup.ag/swap/
        url_part = parts[1].split()[0].split('?')[0].split('#')[0]
        logger.debug(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å URL: {url_part}")

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–µ—Ñ–∏—Å—É –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ TOKEN1-TOKEN2
        if '-' in url_part:
            tokens = url_part.split('-')
            for token in tokens:
                # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                clean_token = ''.join(
                    c for c in token if c in '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz')

                logger.debug(f"üßπ –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: {clean_token}")

                if is_valid_solana_address(clean_token):
                    if not is_wrapped_sol(clean_token):
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π —Ç–æ–∫–µ–Ω: {clean_token}")
                        addresses.append(clean_token)
                    else:
                        logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Wrapped SOL: {clean_token}")
                else:
                    logger.debug(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ç–æ–∫–µ–Ω: {clean_token}")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ URL
        all_potential_tokens = re.findall(r'[A-HJ-NP-Za-km-z1-9]{32,44}', url_part)
        for token in all_potential_tokens:
            if is_valid_solana_address(token) and not is_wrapped_sol(token):
                if token not in addresses:
                    logger.info(f"‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω: {token}")
                    addresses.append(token)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä—É—á–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ Jupiter: {e}")

    return addresses


def extract_addresses_fast(text: str, ai_config) -> List[str]:
    """–£–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    addresses = set()

    # –û–¢–õ–ê–î–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
    logger.debug(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç: {text[:200]}...")

    # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –û–±—Ä–∞–±–æ—Ç–∫–∞ URL –∏–∑ –∏–Ω–ª–∞–π–Ω –∫–Ω–æ–ø–æ–∫ –∏ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫
    import re
    urls_in_text = re.findall(r'https?://[^\s]+', text)
    if urls_in_text:
        logger.info(f"üîó –ù–∞–π–¥–µ–Ω—ã URL –≤ —Ç–µ–∫—Å—Ç–µ: {len(urls_in_text)} —Å—Å—ã–ª–æ–∫")
        for url in urls_in_text:
            url_addresses = extract_addresses_from_any_url(url)
            if url_addresses:
                logger.critical(f"üéØ –ê–î–†–ï–°–ê –ò–ó URL: {url_addresses}")
                addresses.update(url_addresses)

    # –°–ü–ï–¶–ò–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê JUPITER –°–°–´–õ–û–ö (–ü–†–ò–û–†–ò–¢–ï–¢!)
    jupiter_addresses = extract_jupiter_swap_addresses(text)
    if jupiter_addresses:
        logger.critical(f"üéØ JUPITER SWAP –ù–ê–ô–î–ï–ù: {jupiter_addresses}")
        addresses.update(jupiter_addresses)

    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    try:
        patterns = ai_config.solana_address_patterns
        if not patterns:
            logger.warning("‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∞–¥—Ä–µ—Å–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            return list(addresses)
    except AttributeError:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∞–¥—Ä–µ—Å–æ–≤")
        return list(addresses)

    for i, pattern in enumerate(patterns):
        try:
            matches = pattern.findall(text)
            if matches:
                logger.debug(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω {i} –Ω–∞—à–µ–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {matches}")

            for match in matches:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã tuple –∏–∑ –≥—Ä—É–ø–ø
                addr = match if isinstance(match, str) else match[0] if match else ''

                if addr:
                    logger.debug(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–¥—Ä–µ—Å –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ {i}: {addr}")

                    # –°–¢–†–û–ì–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø
                    if is_valid_solana_address(addr):
                        # –§–ò–õ–¨–¢–†–£–ï–ú WRAPPED SOL
                        if is_wrapped_sol(addr):
                            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Wrapped SOL: {addr}")
                            continue

                        logger.info(f"‚úÖ –í–ê–õ–ò–î–ù–´–ô –ê–î–†–ï–° –ù–ê–ô–î–ï–ù: {addr}")
                        addresses.add(addr)
                    else:
                        logger.debug(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –∞–¥—Ä–µ—Å: {addr}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ {i}: {e}")

    # –§–∏–ª—å—Ç—Ä—É–µ–º –∞–¥—Ä–µ—Å–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏
    result = filter_trading_targets(list(addresses))
    logger.info(f"üéØ –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û –¶–ï–õ–ï–í–´–• –¢–û–ö–ï–ù–û–í: {len(result)} | {result}")
    return result


def extract_addresses_from_message_data(message_text: str, inline_urls: List[str] = None,
                                        hyperlink_urls: List[str] = None, ai_config=None) -> List[str]:
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏—è

    Args:
        message_text: –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        inline_urls: URL –∏–∑ –∏–Ω–ª–∞–π–Ω –∫–Ω–æ–ø–æ–∫
        hyperlink_urls: URL –∏–∑ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫
        ai_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AI
    """
    all_addresses = set()

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    text_addresses = extract_addresses_fast(message_text, ai_config)
    all_addresses.update(text_addresses)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL –∏–∑ –∫–Ω–æ–ø–æ–∫
    if inline_urls:
        logger.info(f"üîò –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(inline_urls)} URL –∏–∑ –∏–Ω–ª–∞–π–Ω –∫–Ω–æ–ø–æ–∫")
        for url in inline_urls:
            button_addresses = extract_addresses_from_any_url(url)
            if button_addresses:
                logger.critical(f"üéØ –ö–û–ù–¢–†–ê–ö–¢ –ò–ó –ò–ù–õ–ê–ô–ù –ö–ù–û–ü–ö–ò: {button_addresses}")
                all_addresses.update(button_addresses)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL –∏–∑ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫
    if hyperlink_urls:
        logger.info(f"üîó –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(hyperlink_urls)} –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫")
        for url in hyperlink_urls:
            link_addresses = extract_addresses_from_any_url(url)
            if link_addresses:
                logger.critical(f"üéØ –ö–û–ù–¢–†–ê–ö–¢ –ò–ó –ì–ò–ü–ï–†–°–°–´–õ–ö–ò: {link_addresses}")
                all_addresses.update(link_addresses)

    final_addresses = filter_trading_targets(list(all_addresses))

    if final_addresses:
        logger.critical(f"üö® –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û –ö–û–ù–¢–†–ê–ö–¢–û–í: {len(final_addresses)} | {final_addresses}")

    return final_addresses